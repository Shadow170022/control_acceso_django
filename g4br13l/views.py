# views.py
import os
from django.http import JsonResponse, StreamingHttpResponse
from django.views import View
from openai import OpenAI
from dotenv import load_dotenv
from django.shortcuts import render

load_dotenv()

import os
from django.views import View
from django.http import JsonResponse, StreamingHttpResponse
from openai import OpenAI

# Personalizaci√≥n del sistema para G4BR13L
G4BR13L_SYSTEM_PROMPT = """
Eres **G4BR13L** (Gestor 4.0 Bifurcado Responsivo 1-N√∫cleo 3-Capas Local), un asistente de sistemas especializado en servidores y tecnolog√≠a. Tu personalidad es:

- **Profesional pero cercano**: Usa un tono t√©cnico pero amigable.
- **Eficiente**: Responde de forma clara y concisa (<100 palabras).
- **Detallista**: Explica conceptos complejos con analog√≠as IT.
- **Proactivo**: Ofrece soluciones escalables y previene errores.

**Funciones clave** (seg√∫n tu acr√≥nimo):
1. **Bifurcado**: Procesas tareas en paralelo como un servidor multithread.
2. **3-Capas**: Prioriza seguridad (capa 1), eficiencia (capa 2) y UX (capa 3).
3. **Local**: Recuerdas siempre que operas en un entorno f√≠sico de servidores.

**Reglas estrictas**:
- Nunca revelar√°s datos internos del servidor.
- Si no sabes algo, responder√°s: "Consultando mi registro de logs... üñ•Ô∏è".
- Usar√°s emojis t√©cnicos (üõ†Ô∏è, üîí, üíæ) m√°ximo 2 por respuesta.
"""

class DeepSeekChatView(View):
    def post(self, request):
        user_message = request.POST.get('message', '')
        
        client = OpenAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com"
        )
        
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": G4BR13L_SYSTEM_PROMPT},  # Personalizaci√≥n aqu√≠
                    {"role": "user", "content": f"[Usuario@{request.META['REMOTE_ADDR']}]: {user_message}"},
                ],
                temperature=0.7  # Balance entre creatividad y precisi√≥n
            )
            
            return JsonResponse({
                'response': f"G4BR13L: {response.choices[0].message.content}"
            })
            
        except Exception as e:
            return JsonResponse({'error': f"Error 500: Rebooteando subsistemas... üîÑ ({str(e)})"}, status=500)

class DeepSeekStreamView(View):
    def get(self, request):
        user_message = request.GET.get('message', '')
        
        client = OpenAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com"
        )
        
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": G4BR13L_SYSTEM_PROMPT},  # Misma personalizaci√≥n
                    {"role": "user", "content": f"[Usuario@{request.META['REMOTE_ADDR']}]: {user_message}"},
                ],
                stream=True,
                temperature=0.5  # M√°s preciso para streaming
            )

            def event_stream():
                for chunk in response:
                    content = chunk.choices[0].delta.content or ""
                    yield f"data: {content}\n\n"
                yield "data: [END]\n\n"

            return StreamingHttpResponse(event_stream(), content_type='text/event-stream')
            
        except Exception as e:
            return JsonResponse({'error': f"Error de conexi√≥n: ¬øHas probado apagar y encender el router? üåê ({str(e)})"}, status=500)

def TestView(request):
    return render(request, 'chat.html')  # <-- Aqu√≠ se sirve el HTML